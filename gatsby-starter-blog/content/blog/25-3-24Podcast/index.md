---
title: Key Takeaways from Azure Cloud Talk on AI
date: "2025-03-23T22:10:03.284Z"
description: In a recent episode of Azure Cloud Talk, Brian and I dove headfirst into the dynamic and rapidly evolving world of AI, with a particular focus on its place within the Microsoft Azure ecosystem.
---

<iframe width="560" height="315" src="https://www.youtube.com/embed/1jNcssZLwUI?si=8DEnU9j94byBu-S5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Key Takeaways from Azure Cloud Talk on AI

Brian and I recently talked about the fast-moving world of AI, especially how it fits into Microsoft Azure. We tried to make it more than just a list of facts, aiming for a real discussion about what's happening with AI and offering some useful advice.

We started by talking about how important it is to connect with people in person, like at the MVP Summit. Online stuff is good, but it doesn't replace the value of those casual conversations where you really learn a lot.

Then, we got into how quickly things are changing in tech. Brian and I admitted it can be hard to keep up, particularly with AI developing so fast.

One of the most interesting parts of our chat was about how AI might affect our thinking skills. We discussed a study by Carnegie Mellon and Microsoft that suggests relying too much on AI tools like ChatGPT could actually make it harder for us to think for ourselves and solve problems. I even brought up my own experience using ChatGPT for a home improvement project. It was super helpful, but it also made me wonder if we're losing something when we let AI do the heavy lifting.

After that, we moved on to the basics of AI, like "tokens," the different kinds of AI models, and how to get them running in Azure. We pointed to Azure AI Foundry as a pretty easy way to get started with this.

Of course, we had to talk about money. Brian and I addressed concerns about how much AI might cost, especially with those "tokens." But we reassured people that it's not too bad for most things you'd want to do.

Then, we got into the nitty-gritty of building AI solutions in Azure. We covered the key parts: Azure AI instances, embedding models, and Azure AI Search. We also looked at Cosmos DB and how it can store embeddings, and how to pick the best way to organize your data there.

Brian and I also explained the difference between streaming and asynchronous APIs when working with AI models. We highlighted why asynchronous calls can be better for handling data in your applications.

Finally, we broke down "embeddings" and why they're so important for making AI search work well.

Basically, our Azure Cloud Talk episode tried to give a balanced view of AI in Azure. We were excited about what it can do but also pointed out the challenges and downsides. We think it's important to use AI responsibly, with a good understanding of how it works and what it means for the future.
